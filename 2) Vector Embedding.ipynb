{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Face_Recognition_System_Model\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import hashlib\n",
    "import chromadb\n",
    "import numpy as np\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_hash(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Compute MD5 hash for a file.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        file_bytes = f.read()\n",
    "    return hashlib.md5(file_bytes).hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_class_folders(\n",
    "    base_path: str = \"augmented-lfw-deepfunneled\",\n",
    "    image_size: tuple = (160, 160),\n",
    "    model_name: str = \"Facenet\",\n",
    "    persist_directory: str = \"chroma_db\"  # Directory where the DB will be saved.\n",
    "):\n",
    "    \"\"\"\n",
    "    For each person (class) folder in the dataset, detect, align, and normalize faces in each unique image using DeepFace,\n",
    "    generate embeddings for the aligned face, compute the average embedding, and store it in a persistent local Chroma \n",
    "    collection. Duplicate images (checked via file hash) are skipped.\n",
    "    \n",
    "    Args:\n",
    "        base_path (str): Path to the dataset with one folder per person.\n",
    "        image_size (tuple): Target size for the aligned face images.\n",
    "        model_name (str): DeepFace model to use (e.g., \"Facenet\").\n",
    "        persist_directory (str): Directory where the Chroma database will be stored.\n",
    "    \n",
    "    Returns:\n",
    "        collection: The Chroma collection containing face embeddings.\n",
    "    \"\"\"\n",
    "    # Initialize the persistent Chroma client.\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    \n",
    "    # (Optional) Check the heartbeat to ensure the client is connected.\n",
    "    print(\"Chroma client heartbeat (ns):\", client.heartbeat())\n",
    "    \n",
    "    collection = client.get_or_create_collection(name=\"face_embeddings\")\n",
    "\n",
    "    # Loop over each person's folder.\n",
    "    for person in os.listdir(base_path):\n",
    "        person_dir = os.path.join(base_path, person)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "\n",
    "        embeddings = []  # Collect embeddings for this person.\n",
    "        seen_hashes = set()  # Track image hashes to avoid duplicate embeddings.\n",
    "        \n",
    "        # Process each image in the person's folder.\n",
    "        for image_file in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_file)\n",
    "            \n",
    "            # Compute hash and check for duplicates.\n",
    "            try:\n",
    "                file_hash = get_image_hash(image_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {image_path}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            if file_hash in seen_hashes:\n",
    "                print(f\"Duplicate image skipped: {image_path}\")\n",
    "                continue\n",
    "            seen_hashes.add(file_hash)\n",
    "            \n",
    "            # Face detection, alignment, and normalization.\n",
    "            try:\n",
    "                # Extract faces; returns a list of dicts with keys \"face\" (aligned image) and \"facial_area\"\n",
    "                faces = DeepFace.extract_faces(\n",
    "                    img_path=image_path,\n",
    "                    detector_backend=\"opencv\",\n",
    "                    enforce_detection=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Face detection failed for {image_path}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            if not faces:\n",
    "                print(f\"No face detected in {image_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Use the first detected face (aligned and normalized).\n",
    "            aligned_face = faces[0][\"face\"]\n",
    "            # Resize the aligned face to the target size.\n",
    "            aligned_face = cv2.resize(aligned_face, image_size)\n",
    "            \n",
    "            # Generate embedding from the aligned face.\n",
    "            try:\n",
    "                # Pass the aligned face as a positional argument.\n",
    "                representation = DeepFace.represent(\n",
    "                    aligned_face,\n",
    "                    model_name=model_name,\n",
    "                    enforce_detection=False\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating embedding for {image_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if representation and len(representation) > 0:\n",
    "                embedding = representation[0][\"embedding\"]\n",
    "                embeddings.append(embedding)\n",
    "        \n",
    "        # If unique embeddings were found for this person, average them and store in the collection.\n",
    "        if embeddings:\n",
    "            avg_embedding = np.mean(embeddings, axis=0).tolist()\n",
    "            collection.add(\n",
    "                ids=[person],\n",
    "                embeddings=[avg_embedding],\n",
    "                metadatas=[{\"name\": person, \"num_images\": len(embeddings)}]\n",
    "            )\n",
    "            \n",
    "            print(f\"Added {person} with {len(embeddings)} unique images.\")\n",
    "        else:\n",
    "            print(f\"No embeddings computed for {person}.\")\n",
    "    \n",
    "    # Data is automatically persisted by PersistentClient.\n",
    "    return collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma client heartbeat (ns): 1743173315462164100\n",
      "Added Aaron_Eckhart with 1 unique images.\n",
      "Added Aaron_Guiel with 1 unique images.\n",
      "Added Aaron_Patterson with 1 unique images.\n",
      "Added Aaron_Peirsol with 4 unique images.\n",
      "Added Aaron_Pena with 1 unique images.\n",
      "Added Aaron_Sorkin with 2 unique images.\n",
      "Added Aaron_Tippin with 1 unique images.\n",
      "Added Abbas_Kiarostami with 1 unique images.\n",
      "Added Abba_Eban with 1 unique images.\n",
      "Added Abdel_Aziz_Al-Hakim with 1 unique images.\n",
      "Added Abdel_Madi_Shabneh with 1 unique images.\n",
      "Added Abdel_Nasser_Assidi with 2 unique images.\n",
      "Added Abdoulaye_Wade with 4 unique images.\n",
      "Added Abdulaziz_Kamilov with 1 unique images.\n",
      "Added Abdullah with 4 unique images.\n",
      "Added Abdullah_Ahmad_Badawi with 1 unique images.\n",
      "Added Abdullah_al-Attiyah with 3 unique images.\n",
      "Added Abdullah_Nasseef with 1 unique images.\n",
      "Added Abdullatif_Sener with 2 unique images.\n",
      "Added Abdul_Majeed_Shobokshi with 1 unique images.\n",
      "Added Abdul_Rahman with 1 unique images.\n",
      "Added Abel_Aguilar with 1 unique images.\n",
      "Added Abel_Pacheco with 4 unique images.\n",
      "Added Abid_Hamid_Mahmud_Al-Tikriti with 3 unique images.\n",
      "Added Abner_Martinez with 1 unique images.\n",
      "Added Abraham_Foxman with 1 unique images.\n",
      "Added Aby_Har-Even with 1 unique images.\n",
      "Added Adam_Ant with 1 unique images.\n",
      "Added Adam_Freier with 1 unique images.\n",
      "Added Adam_Herbert with 1 unique images.\n",
      "Added Adam_Kennedy with 1 unique images.\n",
      "Added Adam_Mair with 1 unique images.\n",
      "Added Adam_Rich with 1 unique images.\n",
      "Added Adam_Sandler with 4 unique images.\n",
      "Added Adam_Scott with 2 unique images.\n",
      "Added Adelina_Avila with 1 unique images.\n",
      "Added Adel_Al-Jubeir with 3 unique images.\n",
      "Added Adisai_Bodharamik with 1 unique images.\n",
      "Added Adolfo_Aguilar_Zinser with 3 unique images.\n",
      "Added Adolfo_Rodriguez_Saa with 2 unique images.\n",
      "Added Adoor_Gopalakarishnan with 1 unique images.\n",
      "Added Adriana_Lima with 1 unique images.\n",
      "Added Adriana_Perez_Navarro with 1 unique images.\n",
      "Added Adrianna_Zuzic with 1 unique images.\n",
      "Added Adrian_Annus with 1 unique images.\n",
      "Added Adrian_Fernandez with 1 unique images.\n",
      "Added Adrian_McPherson with 2 unique images.\n",
      "Added Adrian_Murrell with 1 unique images.\n",
      "Added Adrian_Nastase with 2 unique images.\n",
      "Added Atom_Egoyan with 1 unique images.\n"
     ]
    }
   ],
   "source": [
    "collection = vectorize_class_folders(\n",
    "    base_path=\"lfw-deepfunneled-50class\",\n",
    "    image_size=(160, 160),\n",
    "    model_name=\"Facenet\",\n",
    "    persist_directory=\"chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embeddings in the collection: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of embeddings in the collection:\", len(collection.get()['ids']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
